{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba29729184724118",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "import xgboost as xgb\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from glob import glob\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1725a6b233e80fb3",
   "metadata": {},
   "source": [
    "## Prepare Datasets for Machine Learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f4da9cd84bf462",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load data\n",
    "def load_data(file_path):\n",
    "    df = pd.read_csv(file_path, sep='\\t', na_values=['NA', 'null', ''])\n",
    "    return df\n",
    "\n",
    "# Preprocessing function\n",
    "def preprocess_data(df):\n",
    "    # Creating a copy to avoid SettingWithCopyWarning\n",
    "    df = df.copy()\n",
    "    \n",
    "    # Selecting the relevant columns\n",
    "    relevant_columns = ['IMPACT', 'alleles', 'CHROM', 'REF', 'ALT', 'QUAL', 'AC', 'AF', 'AN', 'DB', 'DP', 'ExcessHet', 'FS', 'MLEAC', 'MLEAF', 'MQ', 'MQRankSum', 'QD', 'ReadPosRankSum', 'SOR', 'MAX_AF', 'BLOCKAVG_min30p3a', 'SNVSB', 'SNVHPOL']\n",
    "    df = df[relevant_columns]\n",
    "\n",
    "    # Impact mapping using .loc to avoid SettingWithCopyWarning\n",
    "    impact_mapping = {'HIGH': 0, 'MODERATE': 1, 'LOW': 2, 'MODIFIER': 3}\n",
    "    df.loc[:, 'IMPACT'] = df['IMPACT'].map(impact_mapping)\n",
    "\n",
    "    # Handling categorical columns that are not ordinal\n",
    "    categorical_cols = ['alleles', 'CHROM', 'REF', 'ALT', 'DB']\n",
    "    label_encoders = {}\n",
    "    for col in categorical_cols:\n",
    "        le = LabelEncoder()\n",
    "        df.loc[:, col] = le.fit_transform(df[col].astype(str))  # Ensure all data are string\n",
    "        label_encoders[col] = le\n",
    "\n",
    "    # Handle NaN before converting True/False to 1/0\n",
    "    df['BLOCKAVG_min30p3a'] = df['BLOCKAVG_min30p3a'].fillna(-1)  # Placeholder for NaN\n",
    "    df['BLOCKAVG_min30p3a'] = df['BLOCKAVG_min30p3a'].astype(int)\n",
    "\n",
    "    # Fill remaining missing values with np.nan (if applicable)\n",
    "    df.fillna(value=np.nan, inplace=True)\n",
    "\n",
    "    return df\n",
    "\n",
    "# Main function to load, preprocess, and save data\n",
    "def process_and_save_file(input_file_path, output_file_path):\n",
    "    df = load_data(input_file_path)\n",
    "    df_processed = preprocess_data(df)\n",
    "    df_processed.to_csv(output_file_path, index=False, sep='\\t')\n",
    "    print(f\"Data processed and saved to {output_file_path}\")\n",
    "\n",
    "# File paths\n",
    "input_file_path = '/mnt/sdb/markus-bsc-thesis-data/machine-learning/negative_group_aggregated.tsv'\n",
    "output_file_path = '/mnt/sdb/markus-bsc-thesis-data/machine-learning/ML_prepped_negative_group_aggregated.tsv'\n",
    "\n",
    "# Process and save the file\n",
    "process_and_save_file(input_file_path, output_file_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4fdd282edf59f4b",
   "metadata": {},
   "source": [
    "## Divide Data into Training Testing and Validation Sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b4a4c23a6f1f2e4",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-10T08:33:12.966836Z",
     "start_time": "2024-05-10T08:33:12.731749Z"
    }
   },
   "outputs": [],
   "source": [
    "def load_data(base_dir, group_name):\n",
    "    tsv_dir = os.path.join(base_dir, group_name, 'scaled')\n",
    "    files = glob(os.path.join(tsv_dir, \"*.tsv\"))\n",
    "    data_list = [pd.read_csv(file, sep='\\t') for file in files]\n",
    "    if data_list:\n",
    "        data = pd.concat(data_list)\n",
    "        data['group'] = group_name\n",
    "    else:\n",
    "        data = pd.DataFrame()\n",
    "    return data\n",
    "\n",
    "def load_all_groups(base_directory):\n",
    "    groups = [\"positive-group\", \"negative-group\"]  # Updated list of groups\n",
    "    data_frames = {}\n",
    "    for group in groups:\n",
    "        data_frames[group] = load_data(base_directory, group)\n",
    "        data_frames[group]['label'] = group\n",
    "    #print(data_frames, \"Data frames loaded successfully.\")\n",
    "    return data_frames\n",
    "\n",
    "def prepare_datasets(data_frames):\n",
    "    data_positive = data_frames[\"positive-group\"]\n",
    "    data_negative = data_frames[\"negative-group\"]\n",
    "    \n",
    "    # Splitting positive data into training, validation, and testing sets\n",
    "    data_pos_train, data_pos_test = train_test_split(data_positive, test_size=0.2, random_state=42)\n",
    "    data_pos_train, data_pos_val = train_test_split(data_pos_train, test_size=0.33, random_state=42)\n",
    "\n",
    "    # Concatenating with negative data\n",
    "    training_data = pd.concat([data_pos_train, data_negative.sample(n=len(data_pos_train), random_state=42)])\n",
    "    validation_data = pd.concat([data_pos_val, data_negative.sample(n=len(data_pos_val), random_state=42)])\n",
    "    testing_data = pd.concat([data_pos_test, data_negative.sample(n=len(data_pos_test), random_state=42)])\n",
    "\n",
    "    print(\"Finished dataset preparation...\")\n",
    "    #print(training_data, \"Training data\")\n",
    "    #print(validation_data, \"Validation data\")\n",
    "    #print(testing_data, \"Testing data\")\n",
    "    return training_data, validation_data, testing_data\n",
    "\n",
    "base_directory = '/mnt/sdb/markus-bsc-thesis-data/machine-learning'\n",
    "data_frames = load_all_groups(base_directory)\n",
    "training_data, validation_data, testing_data = prepare_datasets(data_frames)\n",
    "\n",
    "# Optionally, save the datasets to files\n",
    "training_data.to_csv(f\"{base_directory}/training_set.csv\", index=False)\n",
    "validation_data.to_csv(f\"{base_directory}/validation_set.csv\", index=False)\n",
    "testing_data.to_csv(f\"{base_directory}/testing_set.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84b2d855653c2c48",
   "metadata": {},
   "source": [
    "## Train model using XGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ced1d15cef9d887",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load data - ensure this is after you've loaded the data with pd.read_csv or similar\n",
    "training_data = pd.read_csv(f\"{base_directory}/training_set.csv\")\n",
    "validation_data = pd.read_csv(f\"{base_directory}/validation_set.csv\")\n",
    "testing_data = pd.read_csv(f\"{base_directory}/testing_set.csv\")\n",
    "\n",
    "scaler = StandardScaler()\n",
    "training_data_scaled = scaler.fit_transform(training_data.drop(['label'], axis=1))\n",
    "training_data_scaled = pd.DataFrame(training_data_scaled, columns=training_data.columns[:-1])\n",
    "training_data_scaled['label'] = training_data['label'].map({'positive-group': 1, 'negative-group': 0})\n",
    "\n",
    "scaler = StandardScaler()\n",
    "validation_data_scaled = scaler.fit_transform(validation_data.drop(['label'], axis=1))\n",
    "validation_data_scaled = pd.DataFrame(validation_data_scaled, columns=validation_data.columns[:-1])\n",
    "validation_data_scaled['label'] = validation_data['label'].map({'positive-group': 1, 'negative-group': 0})\n",
    "\n",
    "scaler = StandardScaler()\n",
    "testing_data_scaled = scaler.fit_transform(testing_data.drop(['label'], axis=1))\n",
    "testing_data_scaled = pd.DataFrame(testing_data_scaled, columns=testing_data.columns[:-1])\n",
    "testing_data_scaled['label'] = testing_data['label'].map({'positive-group': 1, 'negative-group': 0})\n",
    "\n",
    "\n",
    "# Define relevant columns and categorical columns, including label for preprocessing\n",
    "relevant_columns = ['IMPACT', 'alleles', 'CHROM', 'REF', 'ALT', 'QUAL', 'AC', 'AF', 'AN', 'DB', 'DP', 'ExcessHet', 'FS', 'MLEAC', 'MLEAF', 'MQ', 'MQRankSum', 'QD', 'ReadPosRankSum', 'SOR', 'MAX_AF', 'BLOCKAVG_min30p3a', 'SNVSB', 'SNVHPOL', 'label']\n",
    "categorical_cols = ['alleles', 'CHROM', 'REF', 'ALT', 'DB']\n",
    "\n",
    "# Prepare datasets for training by selecting relevant columns and encoding categorical features\n",
    "def prepare_for_training(data, relevant_columns, categorical_cols):\n",
    "    data = data[relevant_columns].copy()  # Select relevant columns, including label\n",
    "    label_encoder = LabelEncoder()\n",
    "    for col in categorical_cols:\n",
    "        data[col] = label_encoder.fit_transform(data[col])\n",
    "    return data\n",
    "\n",
    "training_data = prepare_for_training(training_data, relevant_columns, categorical_cols)\n",
    "validation_data = prepare_for_training(validation_data, relevant_columns, categorical_cols)\n",
    "testing_data = prepare_for_training(testing_data, relevant_columns, categorical_cols)\n",
    "\n",
    "print(training_data.describe())\n",
    "print(training_data.head())\n",
    "\n",
    "# Convert to DMatrix, preserving label\n",
    "dtrain = xgb.DMatrix(training_data.drop(['label'], axis=1), label=training_data['label'].map({'positive-group': 1, 'negative-group': 0}))\n",
    "dval = xgb.DMatrix(validation_data.drop(['label'], axis=1), label=validation_data['label'].map({'positive-group': 1, 'negative-group': 0}))\n",
    "dtest = xgb.DMatrix(testing_data.drop(['label'], axis=1), label=testing_data['label'].map({'positive-group': 1, 'negative-group': 0}))\n",
    "\n",
    "# Parameters for XGBoost\n",
    "params = {\n",
    "    'max_depth': 5,\n",
    "    'objective': 'binary:logistic',\n",
    "    'eta': 0.1,\n",
    "    'eval_metric': 'logloss',\n",
    "    'random_state': 42\n",
    "}\n",
    "num_rounds = 100\n",
    "\n",
    "# Training the model\n",
    "model = xgb.train(params, dtrain, num_rounds, evals=[(dtrain, 'train'), (dval, 'validation')])\n",
    "\n",
    "# Predictions and Evaluation\n",
    "predictions_proba = model.predict(dtest)\n",
    "predictions = [1 if p >= 0.5 else 0 for p in predictions_proba]\n",
    "accuracy = accuracy_score(testing_data['label'].map({'positive-group': 1, 'negative-group': 0}), predictions)\n",
    "#print(\"Test Accuracy:\", accuracy)\n",
    "\n",
    "# Plotting feature importance\n",
    "xgb.plot_importance(model)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
