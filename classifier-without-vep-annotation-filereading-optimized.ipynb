{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "65662546-607c-47d4-8359-b313a18e51c5",
   "metadata": {},
   "source": [
    "# GenomeMLModels\n",
    "\n",
    "## Introduction\n",
    "This project aims to generate usable machine learning models for clinical datasets. \n",
    "\n",
    "The project incorporates the Hail data handling layer for inputting VCF/gVCF files, facilitating the analysis of datasets from various generations.\n",
    "\n",
    "## Objectives\n",
    "- To train a model on the Illumina Trusight Cancer(TM) and Trusight(TM) Hereditary Cancer panel VCFs.\n",
    "- To annotate variants in new VCFs for potential pathogenicity based on the input phenotype.\n",
    "- To select a decision boundary for single high probability variants, enabling quick downselection of variants or tagging of VCF files for potential monogenic variants.\n",
    "\n",
    "This serves as a proof-of-concept for applying machine learning to genomic datasets using specified libraries.\n",
    "\n",
    "## Data Structure\n",
    "The project expects VCFs or gVCFs with genotype caller allele data and VEP annotations such as IMPACT, MAX_AF, and HGNC_ID. \n",
    "These annotations are converted into features for the model.\n",
    "\n",
    "## Model Specification\n",
    "\n",
    "A boosted decision tree model forms the backbone of our analytical approach, accommodating the complex nature of genomic data, which encompasses both categorical (strings) and continuous (float values) variables. This model will leverage existing open-source machine learning frameworks to optimize its predictive capabilities\n",
    "\n",
    "\n",
    "- There are two directories named cancer and non-cancer. Each will have directories as patient and vcf files are inside patient directories\n",
    "\n",
    "- We have GRCh37 as reference\n",
    "\n",
    "- Forst 5 columns are named as \"CHROM\"\t\"POS\"\t\"ID\"\t\"REF\"\t\"ALT\" in all vcf/gvcf files\n",
    "\n",
    "-  A patient may have complete data in single or multiple vcf files but in same patient's directory and directory name is taken as patient name"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "abbc0749-76e1-4786-9ea3-d1798cc8a079",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c8b6cabf-6d4c-4890-a1fb-b11cbc17927d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>\n",
       "        .bk-notebook-logo {\n",
       "            display: block;\n",
       "            width: 20px;\n",
       "            height: 20px;\n",
       "            background-image: url(data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAABQAAAAUCAYAAACNiR0NAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAABx0RVh0U29mdHdhcmUAQWRvYmUgRmlyZXdvcmtzIENTNui8sowAAAOkSURBVDiNjZRtaJVlGMd/1/08zzln5zjP1LWcU9N0NkN8m2CYjpgQYQXqSs0I84OLIC0hkEKoPtiH3gmKoiJDU7QpLgoLjLIQCpEsNJ1vqUOdO7ppbuec5+V+rj4ctwzd8IIbbi6u+8f1539dt3A78eXC7QizUF7gyV1fD1Yqg4JWz84yffhm0qkFqBogB9rM8tZdtwVsPUhWhGcFJngGeWrPzHm5oaMmkfEg1usvLFyc8jLRqDOMru7AyC8saQr7GG7f5fvDeH7Ej8CM66nIF+8yngt6HWaKh7k49Soy9nXurCi1o3qUbS3zWfrYeQDTB/Qj6kX6Ybhw4B+bOYoLKCC9H3Nu/leUTZ1JdRWkkn2ldcCamzrcf47KKXdAJllSlxAOkRgyHsGC/zRday5Qld9DyoM4/q/rUoy/CXh3jzOu3bHUVZeU+DEn8FInkPBFlu3+nW3Nw0mk6vCDiWg8CeJaxEwuHS3+z5RgY+YBR6V1Z1nxSOfoaPa4LASWxxdNp+VWTk7+4vzaou8v8PN+xo+KY2xsw6une2frhw05CTYOmQvsEhjhWjn0bmXPjpE1+kplmmkP3suftwTubK9Vq22qKmrBhpY4jvd5afdRA3wGjFAgcnTK2s4hY0/GPNIb0nErGMCRxWOOX64Z8RAC4oCXdklmEvcL8o0BfkNK4lUg9HTl+oPlQxdNo3Mg4Nv175e/1LDGzZen30MEjRUtmXSfiTVu1kK8W4txyV6BMKlbgk3lMwYCiusNy9fVfvvwMxv8Ynl6vxoByANLTWplvuj/nF9m2+PDtt1eiHPBr1oIfhCChQMBw6Aw0UulqTKZdfVvfG7VcfIqLG9bcldL/+pdWTLxLUy8Qq38heUIjh4XlzZxzQm19lLFlr8vdQ97rjZVOLf8nclzckbcD4wxXMidpX30sFd37Fv/GtwwhzhxGVAprjbg0gCAEeIgwCZyTV2Z1REEW8O4py0wsjeloKoMr6iCY6dP92H6Vw/oTyICIthibxjm/DfN9lVz8IqtqKYLUXfoKVMVQVVJOElGjrnnUt9T9wbgp8AyYKaGlqingHZU/uG2NTZSVqwHQTWkx9hxjkpWDaCg6Ckj5qebgBVbT3V3NNXMSiWSDdGV3hrtzla7J+duwPOToIg42ChPQOQjspnSlp1V+Gjdged7+8UN5CRAV7a5EdFNwCjEaBR27b3W890TE7g24NAP/mMDXRWrGoFPQI9ls/MWO2dWFAar/xcOIImbbpA3zgAAAABJRU5ErkJggg==);\n",
       "        }\n",
       "    </style>\n",
       "    <div>\n",
       "        <a href=\"https://bokeh.org\" target=\"_blank\" class=\"bk-notebook-logo\"></a>\n",
       "        <span id=\"e19b18c5-3abf-4e8b-9a53-1e708af78952\">Loading BokehJS ...</span>\n",
       "    </div>\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/javascript": [
       "(function(root) {\n",
       "  function now() {\n",
       "    return new Date();\n",
       "  }\n",
       "\n",
       "  const force = true;\n",
       "\n",
       "  if (typeof root._bokeh_onload_callbacks === \"undefined\" || force === true) {\n",
       "    root._bokeh_onload_callbacks = [];\n",
       "    root._bokeh_is_loading = undefined;\n",
       "  }\n",
       "\n",
       "const JS_MIME_TYPE = 'application/javascript';\n",
       "  const HTML_MIME_TYPE = 'text/html';\n",
       "  const EXEC_MIME_TYPE = 'application/vnd.bokehjs_exec.v0+json';\n",
       "  const CLASS_NAME = 'output_bokeh rendered_html';\n",
       "\n",
       "  /**\n",
       "   * Render data to the DOM node\n",
       "   */\n",
       "  function render(props, node) {\n",
       "    const script = document.createElement(\"script\");\n",
       "    node.appendChild(script);\n",
       "  }\n",
       "\n",
       "  /**\n",
       "   * Handle when an output is cleared or removed\n",
       "   */\n",
       "  function handleClearOutput(event, handle) {\n",
       "    function drop(id) {\n",
       "      const view = Bokeh.index.get_by_id(id)\n",
       "      if (view != null) {\n",
       "        view.model.document.clear()\n",
       "        Bokeh.index.delete(view)\n",
       "      }\n",
       "    }\n",
       "\n",
       "    const cell = handle.cell;\n",
       "\n",
       "    const id = cell.output_area._bokeh_element_id;\n",
       "    const server_id = cell.output_area._bokeh_server_id;\n",
       "\n",
       "    // Clean up Bokeh references\n",
       "    if (id != null) {\n",
       "      drop(id)\n",
       "    }\n",
       "\n",
       "    if (server_id !== undefined) {\n",
       "      // Clean up Bokeh references\n",
       "      const cmd_clean = \"from bokeh.io.state import curstate; print(curstate().uuid_to_server['\" + server_id + \"'].get_sessions()[0].document.roots[0]._id)\";\n",
       "      cell.notebook.kernel.execute(cmd_clean, {\n",
       "        iopub: {\n",
       "          output: function(msg) {\n",
       "            const id = msg.content.text.trim()\n",
       "            drop(id)\n",
       "          }\n",
       "        }\n",
       "      });\n",
       "      // Destroy server and session\n",
       "      const cmd_destroy = \"import bokeh.io.notebook as ion; ion.destroy_server('\" + server_id + \"')\";\n",
       "      cell.notebook.kernel.execute(cmd_destroy);\n",
       "    }\n",
       "  }\n",
       "\n",
       "  /**\n",
       "   * Handle when a new output is added\n",
       "   */\n",
       "  function handleAddOutput(event, handle) {\n",
       "    const output_area = handle.output_area;\n",
       "    const output = handle.output;\n",
       "\n",
       "    // limit handleAddOutput to display_data with EXEC_MIME_TYPE content only\n",
       "    if ((output.output_type != \"display_data\") || (!Object.prototype.hasOwnProperty.call(output.data, EXEC_MIME_TYPE))) {\n",
       "      return\n",
       "    }\n",
       "\n",
       "    const toinsert = output_area.element.find(\".\" + CLASS_NAME.split(' ')[0]);\n",
       "\n",
       "    if (output.metadata[EXEC_MIME_TYPE][\"id\"] !== undefined) {\n",
       "      toinsert[toinsert.length - 1].firstChild.textContent = output.data[JS_MIME_TYPE];\n",
       "      // store reference to embed id on output_area\n",
       "      output_area._bokeh_element_id = output.metadata[EXEC_MIME_TYPE][\"id\"];\n",
       "    }\n",
       "    if (output.metadata[EXEC_MIME_TYPE][\"server_id\"] !== undefined) {\n",
       "      const bk_div = document.createElement(\"div\");\n",
       "      bk_div.innerHTML = output.data[HTML_MIME_TYPE];\n",
       "      const script_attrs = bk_div.children[0].attributes;\n",
       "      for (let i = 0; i < script_attrs.length; i++) {\n",
       "        toinsert[toinsert.length - 1].firstChild.setAttribute(script_attrs[i].name, script_attrs[i].value);\n",
       "        toinsert[toinsert.length - 1].firstChild.textContent = bk_div.children[0].textContent\n",
       "      }\n",
       "      // store reference to server id on output_area\n",
       "      output_area._bokeh_server_id = output.metadata[EXEC_MIME_TYPE][\"server_id\"];\n",
       "    }\n",
       "  }\n",
       "\n",
       "  function register_renderer(events, OutputArea) {\n",
       "\n",
       "    function append_mime(data, metadata, element) {\n",
       "      // create a DOM node to render to\n",
       "      const toinsert = this.create_output_subarea(\n",
       "        metadata,\n",
       "        CLASS_NAME,\n",
       "        EXEC_MIME_TYPE\n",
       "      );\n",
       "      this.keyboard_manager.register_events(toinsert);\n",
       "      // Render to node\n",
       "      const props = {data: data, metadata: metadata[EXEC_MIME_TYPE]};\n",
       "      render(props, toinsert[toinsert.length - 1]);\n",
       "      element.append(toinsert);\n",
       "      return toinsert\n",
       "    }\n",
       "\n",
       "    /* Handle when an output is cleared or removed */\n",
       "    events.on('clear_output.CodeCell', handleClearOutput);\n",
       "    events.on('delete.Cell', handleClearOutput);\n",
       "\n",
       "    /* Handle when a new output is added */\n",
       "    events.on('output_added.OutputArea', handleAddOutput);\n",
       "\n",
       "    /**\n",
       "     * Register the mime type and append_mime function with output_area\n",
       "     */\n",
       "    OutputArea.prototype.register_mime_type(EXEC_MIME_TYPE, append_mime, {\n",
       "      /* Is output safe? */\n",
       "      safe: true,\n",
       "      /* Index of renderer in `output_area.display_order` */\n",
       "      index: 0\n",
       "    });\n",
       "  }\n",
       "\n",
       "  // register the mime type if in Jupyter Notebook environment and previously unregistered\n",
       "  if (root.Jupyter !== undefined) {\n",
       "    const events = require('base/js/events');\n",
       "    const OutputArea = require('notebook/js/outputarea').OutputArea;\n",
       "\n",
       "    if (OutputArea.prototype.mime_types().indexOf(EXEC_MIME_TYPE) == -1) {\n",
       "      register_renderer(events, OutputArea);\n",
       "    }\n",
       "  }\n",
       "  if (typeof (root._bokeh_timeout) === \"undefined\" || force === true) {\n",
       "    root._bokeh_timeout = Date.now() + 5000;\n",
       "    root._bokeh_failed_load = false;\n",
       "  }\n",
       "\n",
       "  const NB_LOAD_WARNING = {'data': {'text/html':\n",
       "     \"<div style='background-color: #fdd'>\\n\"+\n",
       "     \"<p>\\n\"+\n",
       "     \"BokehJS does not appear to have successfully loaded. If loading BokehJS from CDN, this \\n\"+\n",
       "     \"may be due to a slow or bad network connection. Possible fixes:\\n\"+\n",
       "     \"</p>\\n\"+\n",
       "     \"<ul>\\n\"+\n",
       "     \"<li>re-rerun `output_notebook()` to attempt to load from CDN again, or</li>\\n\"+\n",
       "     \"<li>use INLINE resources instead, as so:</li>\\n\"+\n",
       "     \"</ul>\\n\"+\n",
       "     \"<code>\\n\"+\n",
       "     \"from bokeh.resources import INLINE\\n\"+\n",
       "     \"output_notebook(resources=INLINE)\\n\"+\n",
       "     \"</code>\\n\"+\n",
       "     \"</div>\"}};\n",
       "\n",
       "  function display_loaded() {\n",
       "    const el = document.getElementById(\"e19b18c5-3abf-4e8b-9a53-1e708af78952\");\n",
       "    if (el != null) {\n",
       "      el.textContent = \"BokehJS is loading...\";\n",
       "    }\n",
       "    if (root.Bokeh !== undefined) {\n",
       "      if (el != null) {\n",
       "        el.textContent = \"BokehJS \" + root.Bokeh.version + \" successfully loaded.\";\n",
       "      }\n",
       "    } else if (Date.now() < root._bokeh_timeout) {\n",
       "      setTimeout(display_loaded, 100)\n",
       "    }\n",
       "  }\n",
       "\n",
       "  function run_callbacks() {\n",
       "    try {\n",
       "      root._bokeh_onload_callbacks.forEach(function(callback) {\n",
       "        if (callback != null)\n",
       "          callback();\n",
       "      });\n",
       "    } finally {\n",
       "      delete root._bokeh_onload_callbacks\n",
       "    }\n",
       "    console.debug(\"Bokeh: all callbacks have finished\");\n",
       "  }\n",
       "\n",
       "  function load_libs(css_urls, js_urls, callback) {\n",
       "    if (css_urls == null) css_urls = [];\n",
       "    if (js_urls == null) js_urls = [];\n",
       "\n",
       "    root._bokeh_onload_callbacks.push(callback);\n",
       "    if (root._bokeh_is_loading > 0) {\n",
       "      console.debug(\"Bokeh: BokehJS is being loaded, scheduling callback at\", now());\n",
       "      return null;\n",
       "    }\n",
       "    if (js_urls == null || js_urls.length === 0) {\n",
       "      run_callbacks();\n",
       "      return null;\n",
       "    }\n",
       "    console.debug(\"Bokeh: BokehJS not loaded, scheduling load and callback at\", now());\n",
       "    root._bokeh_is_loading = css_urls.length + js_urls.length;\n",
       "\n",
       "    function on_load() {\n",
       "      root._bokeh_is_loading--;\n",
       "      if (root._bokeh_is_loading === 0) {\n",
       "        console.debug(\"Bokeh: all BokehJS libraries/stylesheets loaded\");\n",
       "        run_callbacks()\n",
       "      }\n",
       "    }\n",
       "\n",
       "    function on_error(url) {\n",
       "      console.error(\"failed to load \" + url);\n",
       "    }\n",
       "\n",
       "    for (let i = 0; i < css_urls.length; i++) {\n",
       "      const url = css_urls[i];\n",
       "      const element = document.createElement(\"link\");\n",
       "      element.onload = on_load;\n",
       "      element.onerror = on_error.bind(null, url);\n",
       "      element.rel = \"stylesheet\";\n",
       "      element.type = \"text/css\";\n",
       "      element.href = url;\n",
       "      console.debug(\"Bokeh: injecting link tag for BokehJS stylesheet: \", url);\n",
       "      document.body.appendChild(element);\n",
       "    }\n",
       "\n",
       "    for (let i = 0; i < js_urls.length; i++) {\n",
       "      const url = js_urls[i];\n",
       "      const element = document.createElement('script');\n",
       "      element.onload = on_load;\n",
       "      element.onerror = on_error.bind(null, url);\n",
       "      element.async = false;\n",
       "      element.src = url;\n",
       "      console.debug(\"Bokeh: injecting script tag for BokehJS library: \", url);\n",
       "      document.head.appendChild(element);\n",
       "    }\n",
       "  };\n",
       "\n",
       "  function inject_raw_css(css) {\n",
       "    const element = document.createElement(\"style\");\n",
       "    element.appendChild(document.createTextNode(css));\n",
       "    document.body.appendChild(element);\n",
       "  }\n",
       "\n",
       "  const js_urls = [\"https://cdn.bokeh.org/bokeh/release/bokeh-3.3.0.min.js\", \"https://cdn.bokeh.org/bokeh/release/bokeh-gl-3.3.0.min.js\", \"https://cdn.bokeh.org/bokeh/release/bokeh-widgets-3.3.0.min.js\", \"https://cdn.bokeh.org/bokeh/release/bokeh-tables-3.3.0.min.js\", \"https://cdn.bokeh.org/bokeh/release/bokeh-mathjax-3.3.0.min.js\"];\n",
       "  const css_urls = [];\n",
       "\n",
       "  const inline_js = [    function(Bokeh) {\n",
       "      Bokeh.set_log_level(\"info\");\n",
       "    },\n",
       "function(Bokeh) {\n",
       "    }\n",
       "  ];\n",
       "\n",
       "  function run_inline_js() {\n",
       "    if (root.Bokeh !== undefined || force === true) {\n",
       "          for (let i = 0; i < inline_js.length; i++) {\n",
       "      inline_js[i].call(root, root.Bokeh);\n",
       "    }\n",
       "if (force === true) {\n",
       "        display_loaded();\n",
       "      }} else if (Date.now() < root._bokeh_timeout) {\n",
       "      setTimeout(run_inline_js, 100);\n",
       "    } else if (!root._bokeh_failed_load) {\n",
       "      console.log(\"Bokeh: BokehJS failed to load within specified timeout.\");\n",
       "      root._bokeh_failed_load = true;\n",
       "    } else if (force !== true) {\n",
       "      const cell = $(document.getElementById(\"e19b18c5-3abf-4e8b-9a53-1e708af78952\")).parents('.cell').data().cell;\n",
       "      cell.output_area.append_execute_result(NB_LOAD_WARNING)\n",
       "    }\n",
       "  }\n",
       "\n",
       "  if (root._bokeh_is_loading === 0) {\n",
       "    console.debug(\"Bokeh: BokehJS loaded, going straight to plotting\");\n",
       "    run_inline_js();\n",
       "  } else {\n",
       "    load_libs(css_urls, js_urls, function() {\n",
       "      console.debug(\"Bokeh: BokehJS plotting callback run at\", now());\n",
       "      run_inline_js();\n",
       "    });\n",
       "  }\n",
       "}(window));"
      ],
      "application/vnd.bokehjs_load.v0+json": "(function(root) {\n  function now() {\n    return new Date();\n  }\n\n  const force = true;\n\n  if (typeof root._bokeh_onload_callbacks === \"undefined\" || force === true) {\n    root._bokeh_onload_callbacks = [];\n    root._bokeh_is_loading = undefined;\n  }\n\n\n  if (typeof (root._bokeh_timeout) === \"undefined\" || force === true) {\n    root._bokeh_timeout = Date.now() + 5000;\n    root._bokeh_failed_load = false;\n  }\n\n  const NB_LOAD_WARNING = {'data': {'text/html':\n     \"<div style='background-color: #fdd'>\\n\"+\n     \"<p>\\n\"+\n     \"BokehJS does not appear to have successfully loaded. If loading BokehJS from CDN, this \\n\"+\n     \"may be due to a slow or bad network connection. Possible fixes:\\n\"+\n     \"</p>\\n\"+\n     \"<ul>\\n\"+\n     \"<li>re-rerun `output_notebook()` to attempt to load from CDN again, or</li>\\n\"+\n     \"<li>use INLINE resources instead, as so:</li>\\n\"+\n     \"</ul>\\n\"+\n     \"<code>\\n\"+\n     \"from bokeh.resources import INLINE\\n\"+\n     \"output_notebook(resources=INLINE)\\n\"+\n     \"</code>\\n\"+\n     \"</div>\"}};\n\n  function display_loaded() {\n    const el = document.getElementById(\"e19b18c5-3abf-4e8b-9a53-1e708af78952\");\n    if (el != null) {\n      el.textContent = \"BokehJS is loading...\";\n    }\n    if (root.Bokeh !== undefined) {\n      if (el != null) {\n        el.textContent = \"BokehJS \" + root.Bokeh.version + \" successfully loaded.\";\n      }\n    } else if (Date.now() < root._bokeh_timeout) {\n      setTimeout(display_loaded, 100)\n    }\n  }\n\n  function run_callbacks() {\n    try {\n      root._bokeh_onload_callbacks.forEach(function(callback) {\n        if (callback != null)\n          callback();\n      });\n    } finally {\n      delete root._bokeh_onload_callbacks\n    }\n    console.debug(\"Bokeh: all callbacks have finished\");\n  }\n\n  function load_libs(css_urls, js_urls, callback) {\n    if (css_urls == null) css_urls = [];\n    if (js_urls == null) js_urls = [];\n\n    root._bokeh_onload_callbacks.push(callback);\n    if (root._bokeh_is_loading > 0) {\n      console.debug(\"Bokeh: BokehJS is being loaded, scheduling callback at\", now());\n      return null;\n    }\n    if (js_urls == null || js_urls.length === 0) {\n      run_callbacks();\n      return null;\n    }\n    console.debug(\"Bokeh: BokehJS not loaded, scheduling load and callback at\", now());\n    root._bokeh_is_loading = css_urls.length + js_urls.length;\n\n    function on_load() {\n      root._bokeh_is_loading--;\n      if (root._bokeh_is_loading === 0) {\n        console.debug(\"Bokeh: all BokehJS libraries/stylesheets loaded\");\n        run_callbacks()\n      }\n    }\n\n    function on_error(url) {\n      console.error(\"failed to load \" + url);\n    }\n\n    for (let i = 0; i < css_urls.length; i++) {\n      const url = css_urls[i];\n      const element = document.createElement(\"link\");\n      element.onload = on_load;\n      element.onerror = on_error.bind(null, url);\n      element.rel = \"stylesheet\";\n      element.type = \"text/css\";\n      element.href = url;\n      console.debug(\"Bokeh: injecting link tag for BokehJS stylesheet: \", url);\n      document.body.appendChild(element);\n    }\n\n    for (let i = 0; i < js_urls.length; i++) {\n      const url = js_urls[i];\n      const element = document.createElement('script');\n      element.onload = on_load;\n      element.onerror = on_error.bind(null, url);\n      element.async = false;\n      element.src = url;\n      console.debug(\"Bokeh: injecting script tag for BokehJS library: \", url);\n      document.head.appendChild(element);\n    }\n  };\n\n  function inject_raw_css(css) {\n    const element = document.createElement(\"style\");\n    element.appendChild(document.createTextNode(css));\n    document.body.appendChild(element);\n  }\n\n  const js_urls = [\"https://cdn.bokeh.org/bokeh/release/bokeh-3.3.0.min.js\", \"https://cdn.bokeh.org/bokeh/release/bokeh-gl-3.3.0.min.js\", \"https://cdn.bokeh.org/bokeh/release/bokeh-widgets-3.3.0.min.js\", \"https://cdn.bokeh.org/bokeh/release/bokeh-tables-3.3.0.min.js\", \"https://cdn.bokeh.org/bokeh/release/bokeh-mathjax-3.3.0.min.js\"];\n  const css_urls = [];\n\n  const inline_js = [    function(Bokeh) {\n      Bokeh.set_log_level(\"info\");\n    },\nfunction(Bokeh) {\n    }\n  ];\n\n  function run_inline_js() {\n    if (root.Bokeh !== undefined || force === true) {\n          for (let i = 0; i < inline_js.length; i++) {\n      inline_js[i].call(root, root.Bokeh);\n    }\nif (force === true) {\n        display_loaded();\n      }} else if (Date.now() < root._bokeh_timeout) {\n      setTimeout(run_inline_js, 100);\n    } else if (!root._bokeh_failed_load) {\n      console.log(\"Bokeh: BokehJS failed to load within specified timeout.\");\n      root._bokeh_failed_load = true;\n    } else if (force !== true) {\n      const cell = $(document.getElementById(\"e19b18c5-3abf-4e8b-9a53-1e708af78952\")).parents('.cell').data().cell;\n      cell.output_area.append_execute_result(NB_LOAD_WARNING)\n    }\n  }\n\n  if (root._bokeh_is_loading === 0) {\n    console.debug(\"Bokeh: BokehJS loaded, going straight to plotting\");\n    run_inline_js();\n  } else {\n    load_libs(css_urls, js_urls, function() {\n      console.debug(\"Bokeh: BokehJS plotting callback run at\", now());\n      run_inline_js();\n    });\n  }\n}(window));"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "SLF4J: No SLF4J providers were found.\n",
      "SLF4J: Defaulting to no-operation (NOP) logger implementation\n",
      "SLF4J: See https://www.slf4j.org/codes.html#noProviders for further details.\n",
      "SLF4J: Class path contains SLF4J bindings targeting slf4j-api versions 1.7.x or earlier.\n",
      "SLF4J: Ignoring binding found at [jar:file:/home/mod/env/gene-tool/lib/python3.10/site-packages/pyspark/jars/log4j-slf4j-impl-2.17.2.jar!/org/slf4j/impl/StaticLoggerBinder.class]\n",
      "SLF4J: See https://www.slf4j.org/codes.html#ignoredBindings for an explanation.\n",
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n",
      "Running on Apache Spark version 3.3.3\n",
      "SparkUI available at http://192.168.1.24:4040\n",
      "Welcome to\n",
      "     __  __     <>__\n",
      "    / /_/ /__  __/ /\n",
      "   / __  / _ `/ / /\n",
      "  /_/ /_/\\_,_/_/_/   version 0.2.125-6e6f46797aed\n",
      "LOGGING: writing to /home/mod/gen-toolbox/hail-20240222-1741-0.2.125-6e6f46797aed.log\n"
     ]
    }
   ],
   "source": [
    "import xgboost as xgb\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, mean_squared_error\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from tabpfn import TabPFNClassifier\n",
    "from tabpfn.scripts.decision_boundary import DecisionBoundaryDisplay\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "import csv\n",
    "import glob\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import hail as hl\n",
    "# Initialize Hail\n",
    "hl.init()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e65760d9-fbfe-4f75-a791-7514884e202e",
   "metadata": {},
   "source": [
    "# Data loading and preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b34a6c68-af53-4317-9a2a-0dfb411dc936",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize Hail's reference genome for GRCh37\n",
    "rg = hl.get_reference('GRCh37') \n",
    "\n",
    "# Add sequence data to the reference genome. Paths are specified in the gen-toolbox configuration.\n",
    "rg.add_sequence(\n",
    "    './mod/.vep/homo_sapiens_merged/110_GRCh37/Homo_sapiens.GRCh37.75.dna.primary_assembly.fa',\n",
    "    './mod/.vep/homo_sapiens_merged/110_GRCh37/Homo_sapiens.GRCh37.75.dna.primary_assembly.fa.fai'\n",
    ")\n",
    "\n",
    "# Define the base directory where the data is located\n",
    "base_dir = '/mnt/sdb/tsch_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "44062d3a-99e7-4255-90ab-ba11b7112416",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_sequence_context(row):\n",
    "    \"\"\"\n",
    "    Retrieves the sequence context around a specified genomic position.\n",
    "    \n",
    "    Args:\n",
    "    row (dict): A dictionary or row containing 'CHROM' and 'POS' keys, representing the chromosome\n",
    "                and position of interest.\n",
    "                \n",
    "    Returns:\n",
    "    str: A string representing the sequence context around the given position, including 6 bases\n",
    "         before and 6 bases after the specified position.\n",
    "    \"\"\"\n",
    "    # Extract chromosome and position from the row\n",
    "    chromosome = row['CHROM']\n",
    "    position = row['POS']\n",
    "    \n",
    "    # Create a Hail locus object for the specified chromosome and position\n",
    "    locus = hl.locus(chromosome, position)\n",
    "    \n",
    "    # Retrieve the sequence context around the locus\n",
    "    # Note: The original comment mentioned \"10 bases before and after\" which seems to be a mistake.\n",
    "    # Corrected to accurately describe the parameters used (6 bases before and after).\n",
    "    sequence = hl.eval(locus.sequence_context(before=6, after=6))\n",
    "    \n",
    "    return sequence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2549da4-2633-48b7-9991-84475e79c20b",
   "metadata": {
    "is_executing": true
   },
   "outputs": [],
   "source": [
    "# Initialize an empty DataFrame for storing Minor Allele Frequency (MAF) data or related information\n",
    "maf = pd.DataFrame()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8335fe62-6497-4baf-8211-0392336193e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "paths_list = glob.glob(f'{base_dir}/cancer/*/*') + glob.glob(f'{base_dir}/non-cancer/*/*')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4f12ff09-90dd-4938-9c5d-197101e038d0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['cancer/b/in_silico_sorted2.vcf',\n",
       " 'cancer/b/in_silico_sorted.vcf',\n",
       " 'cancer/c/s2.vcf',\n",
       " 'cancer/c/in_silico_sorted2.vcf',\n",
       " 'cancer/a/in_silico_sorted.vcf',\n",
       " 'non-cancer/e/gatk_allsites2.g.vcf',\n",
       " 'non-cancer/d/gatk_allsites.g.vcf']"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "paths_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "fd2ed99e-174f-4932-b7b1-ae9e63a39065",
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_df(path):\n",
    "    \"\"\"\n",
    "    Reads a TSV file from the specified path into a pandas DataFrame.\n",
    "    \n",
    "    Args:\n",
    "        path (str): The file path of the TSV file to be read.\n",
    "        \n",
    "    Returns:\n",
    "        pd.DataFrame: A DataFrame containing the data from the TSV file, with the first row of data used as column headers.\n",
    "    \"\"\"\n",
    "    # Use the provided path to open the TSV file\n",
    "    with open(path, 'r', newline='', encoding='utf-8') as tsvfile:\n",
    "        # Create a CSV reader object specifying tab ('\\t') as delimiter\n",
    "        reader = csv.reader(tsvfile, delimiter='\\t')\n",
    "        \n",
    "        # Filter out header lines that start with '##' and load the rest into a DataFrame\n",
    "        data = [row for row in reader if not row[0].startswith('##')]\n",
    "        df = pd.DataFrame(data)\n",
    "    \n",
    "    # The first row of actual data is used as column headers\n",
    "    df.columns = df.iloc[0]\n",
    "    df = df.drop(0).reset_index(drop=True)\n",
    "    \n",
    "    # Rename the '#CHROM' column to 'CHROM' for consistency\n",
    "    df.rename(columns={'#CHROM': 'CHROM'}, inplace=True)\n",
    "    \n",
    "    # Optional: Print a confirmation message\n",
    "    print(f\"{path} has been read successfully.\")\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ee3228a-1399-45ea-9df8-cd1d72c3340b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "reading cancer/b/in_silico_sorted2.vcf\n",
      "cancer/b/in_silico_sorted2.vcf  has been read\n",
      "reading cancer/b/in_silico_sorted.vcf\n",
      "cancer/b/in_silico_sorted.vcf  has been read\n",
      "reading cancer/c/s2.vcf\n",
      "cancer/c/s2.vcf  has been read\n",
      "reading cancer/c/in_silico_sorted2.vcf\n",
      "cancer/c/in_silico_sorted2.vcf  has been read\n",
      "reading cancer/a/in_silico_sorted.vcf\n",
      "cancer/a/in_silico_sorted.vcf  has been read\n"
     ]
    }
   ],
   "source": [
    "for path in paths_list:\n",
    "    print(f'Reading {path}')\n",
    "    # Use the refactored read_df function to read the file into a DataFrame\n",
    "    vcf = read_df(path)\n",
    "    \n",
    "    # Select the first five columns and clean up the chromosome names\n",
    "    vcf = vcf.iloc[:, :5]\n",
    "    vcf['CHROM'] = vcf['CHROM'].str.replace('chr', '')\n",
    "    \n",
    "    # Convert position to numeric, handling errors\n",
    "    vcf['POS'] = pd.to_numeric(vcf['POS'], errors='coerce')\n",
    "    \n",
    "    # Apply the get_sequence_context function to each row\n",
    "    vcf['Genome_Plus_Minus_10_Bp'] = vcf.apply(get_sequence_context, axis=1)\n",
    "    \n",
    "    # Add additional metadata columns\n",
    "    vcf['Variant_Type'] = 'SNP'\n",
    "    vcf['Mutation_Status'] = 'Somatic'\n",
    "    vcf['Matched_Norm_Sample_Barcode'] = '/'.join(path.split('/')[-3:-1])\n",
    "    \n",
    "    # Append the processed DataFrame to the master DataFrame\n",
    "    maf = pd.concat([maf, vcf], ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "bcf75f8b-790e-442f-b991-d7d8aa97f865",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CHROM</th>\n",
       "      <th>POS</th>\n",
       "      <th>ID</th>\n",
       "      <th>REF</th>\n",
       "      <th>ALT</th>\n",
       "      <th>Genome_Plus_Minus_10_Bp</th>\n",
       "      <th>Variant_Type</th>\n",
       "      <th>Mutation_Status</th>\n",
       "      <th>Matched_Norm_Sample_Barcode</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>10318652</td>\n",
       "      <td>rs12402052</td>\n",
       "      <td>C</td>\n",
       "      <td>G</td>\n",
       "      <td>TTTTGCCTATGGG</td>\n",
       "      <td>SNP</td>\n",
       "      <td>Somatic</td>\n",
       "      <td>cancer/b</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>10318652</td>\n",
       "      <td>rs12402052</td>\n",
       "      <td>C</td>\n",
       "      <td>G</td>\n",
       "      <td>TTTTGCCTATGGG</td>\n",
       "      <td>SNP</td>\n",
       "      <td>Somatic</td>\n",
       "      <td>cancer/b</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>10327623</td>\n",
       "      <td>rs139613776</td>\n",
       "      <td>T</td>\n",
       "      <td>TA</td>\n",
       "      <td>GTATGGTAGGAAA</td>\n",
       "      <td>SNP</td>\n",
       "      <td>Somatic</td>\n",
       "      <td>cancer/b</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>10328338</td>\n",
       "      <td>rs1339458</td>\n",
       "      <td>C</td>\n",
       "      <td>T</td>\n",
       "      <td>TTCAGTCTCTAGG</td>\n",
       "      <td>SNP</td>\n",
       "      <td>Somatic</td>\n",
       "      <td>cancer/b</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>10328338</td>\n",
       "      <td>rs1339458</td>\n",
       "      <td>C</td>\n",
       "      <td>T</td>\n",
       "      <td>TTCAGTCTCTAGG</td>\n",
       "      <td>SNP</td>\n",
       "      <td>Somatic</td>\n",
       "      <td>cancer/b</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22142</th>\n",
       "      <td>1</td>\n",
       "      <td>19939</td>\n",
       "      <td>.</td>\n",
       "      <td>T</td>\n",
       "      <td>.</td>\n",
       "      <td>TCTGCATTCGAGG</td>\n",
       "      <td>SNP</td>\n",
       "      <td>Somatic</td>\n",
       "      <td>non-cancer/d</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22143</th>\n",
       "      <td>1</td>\n",
       "      <td>19940</td>\n",
       "      <td>.</td>\n",
       "      <td>T</td>\n",
       "      <td>.</td>\n",
       "      <td>CTGCATTCGAGGT</td>\n",
       "      <td>SNP</td>\n",
       "      <td>Somatic</td>\n",
       "      <td>non-cancer/d</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22144</th>\n",
       "      <td>1</td>\n",
       "      <td>19941</td>\n",
       "      <td>.</td>\n",
       "      <td>C</td>\n",
       "      <td>.</td>\n",
       "      <td>TGCATTCGAGGTC</td>\n",
       "      <td>SNP</td>\n",
       "      <td>Somatic</td>\n",
       "      <td>non-cancer/d</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22145</th>\n",
       "      <td>1</td>\n",
       "      <td>19942</td>\n",
       "      <td>.</td>\n",
       "      <td>G</td>\n",
       "      <td>.</td>\n",
       "      <td>GCATTCGAGGTCC</td>\n",
       "      <td>SNP</td>\n",
       "      <td>Somatic</td>\n",
       "      <td>non-cancer/d</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22146</th>\n",
       "      <td>1</td>\n",
       "      <td>19943</td>\n",
       "      <td>.</td>\n",
       "      <td>A</td>\n",
       "      <td>.</td>\n",
       "      <td>CATTCGAGGTCCA</td>\n",
       "      <td>SNP</td>\n",
       "      <td>Somatic</td>\n",
       "      <td>non-cancer/d</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>22147 rows × 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      CHROM       POS           ID REF ALT Genome_Plus_Minus_10_Bp  \\\n",
       "0         1  10318652   rs12402052   C   G           TTTTGCCTATGGG   \n",
       "1         1  10318652   rs12402052   C   G           TTTTGCCTATGGG   \n",
       "2         1  10327623  rs139613776   T  TA           GTATGGTAGGAAA   \n",
       "3         1  10328338    rs1339458   C   T           TTCAGTCTCTAGG   \n",
       "4         1  10328338    rs1339458   C   T           TTCAGTCTCTAGG   \n",
       "...     ...       ...          ...  ..  ..                     ...   \n",
       "22142     1     19939            .   T   .           TCTGCATTCGAGG   \n",
       "22143     1     19940            .   T   .           CTGCATTCGAGGT   \n",
       "22144     1     19941            .   C   .           TGCATTCGAGGTC   \n",
       "22145     1     19942            .   G   .           GCATTCGAGGTCC   \n",
       "22146     1     19943            .   A   .           CATTCGAGGTCCA   \n",
       "\n",
       "      Variant_Type Mutation_Status Matched_Norm_Sample_Barcode  \n",
       "0              SNP         Somatic                    cancer/b  \n",
       "1              SNP         Somatic                    cancer/b  \n",
       "2              SNP         Somatic                    cancer/b  \n",
       "3              SNP         Somatic                    cancer/b  \n",
       "4              SNP         Somatic                    cancer/b  \n",
       "...            ...             ...                         ...  \n",
       "22142          SNP         Somatic                non-cancer/d  \n",
       "22143          SNP         Somatic                non-cancer/d  \n",
       "22144          SNP         Somatic                non-cancer/d  \n",
       "22145          SNP         Somatic                non-cancer/d  \n",
       "22146          SNP         Somatic                non-cancer/d  \n",
       "\n",
       "[22147 rows x 9 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "maf.reset_index(drop=True, inplace=True)\n",
    "maf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "2c546e35-ea6b-4f42-91bd-7c9c283893d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract specific columns from the maf DataFrame\n",
    "gene_13 = maf['Genome_Plus_Minus_10_Bp']\n",
    "gene_re = maf['REF']\n",
    "m_type = maf['Variant_Type']\n",
    "sta = maf['Mutation_Status']\n",
    "alle = maf['ALT']\n",
    "gene_id = maf['Matched_Norm_Sample_Barcode']\n",
    "\n",
    "# Get unique sample barcodes\n",
    "unique_ids = gene_id.unique()\n",
    "\n",
    "# Lists for standardizing mutation notation\n",
    "sig1_orig = [\"G>A\", \"G>T\", \"G>C\", \"A>G\", \"A>T\", \"A>C\"]\n",
    "sig1_repl = [\"C>T\", \"C>A\", \"C>G\", \"T>C\", \"T>A\", \"T>G\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "7dd72597-e0ad-4222-8fe3-df172f87794e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Count subscripts that satisfy the conditions\n",
    "count = 0  # Initialize count to track the number of valid variants\n",
    "index = []  # Initialize a list to keep track of valid variant indices\n",
    "\n",
    "# Loop through each variant based on its index\n",
    "for i in range(len(gene_13)):\n",
    "    # Check if the variant meets the specified conditions:\n",
    "    # 1. Variant type (m_type) should be \"SNP\".\n",
    "    # 2. Mutation status (sta) should be \"Somatic\".\n",
    "    # 3. The sample identifier (gene_id) should be present in the list of unique_ids.\n",
    "    if m_type[i] == \"SNP\" and sta[i] == \"Somatic\" and gene_id[i] in unique_ids:\n",
    "        # If conditions are met, increment the count and add the index to the list\n",
    "        count += 1\n",
    "        index.append(i)\n",
    "\n",
    "# Initialize variables to track errors\n",
    "error_num = 0  # Count of variants that fail the sequence context check\n",
    "error_index = []  # Indices of variants that fail the sequence context check\n",
    "\n",
    "# Iterate over the indices of variants that initially met the conditions\n",
    "for i in index:\n",
    "    # Check if the 7th character of the sequence context (gene_13)\n",
    "    # does NOT match the reference allele (gene_re).\n",
    "    # Note: Python uses 0-based indexing, hence [6] accesses the 7th character.\n",
    "    if gene_13[i][6] != gene_re[i]:\n",
    "        # If it doesn't match, increment error count and record the index\n",
    "        error_num += 1\n",
    "        error_index.append(i)\n",
    "\n",
    "# Filter out indices of variants that failed the sequence context check\n",
    "index = [x for x in index if x not in error_index]\n",
    "# Adjust the count to only include variants that passed all checks\n",
    "count -= error_num"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "3f34b436-42d9-4e46-8611-2c636494a2fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Building a one-dimensional feature matrix - initialize mutation type lists\n",
    "mut1 = []\n",
    "\n",
    "# One-dimensional feature matrix construction\n",
    "for i in range(count):\n",
    "    mutation = gene_13[index[i]][6] + \">\" + alle[index[i]]\n",
    "    mut1.append(mutation)\n",
    "\n",
    "# Standardize the mutations in the one-dimensional feature matrix\n",
    "for j in range(len(mut1)):\n",
    "    for i in range(len(sig1_orig)):\n",
    "        if mut1[j] == sig1_orig[i]:\n",
    "            mut1[j] = sig1_repl[i]\n",
    "\n",
    "# Two-dimensional feature matrices construction with left and right genomic context\n",
    "mut2_l = []\n",
    "mut2_r = []\n",
    "for i in range(count):\n",
    "    mut2_l.append(gene_13[index[i]][5] + \".\" + gene_13[index[i]][6] + \">\" + alle[index[i]])\n",
    "    mut2_r.append(gene_13[index[i]][6] + \">\" + alle[index[i]] + \".\" + gene_13[index[i]][7])\n",
    "\n",
    "# Deduplicate to get unique feature labels\n",
    "sig2_repl_l = list(set(mut2_l))\n",
    "sig2_repl_r = list(set(mut2_r))\n",
    "\n",
    "# Three-dimensional feature matrices construction for left, both sides, and right context\n",
    "mut3_l = []\n",
    "mut3_m = []\n",
    "mut3_r = []\n",
    "for i in range(count):\n",
    "    mut3_l.append(gene_13[index[i]][4] + \".\" + gene_13[index[i]][5] + \".\" + gene_13[index[i]][6] + \">\" + alle[index[i]])\n",
    "    mut3_m.append(gene_13[index[i]][5] + \".\" + gene_13[index[i]][6] + \">\" + alle[index[i]] + \".\" + gene_13[index[i]][7])\n",
    "    mut3_r.append(gene_13[index[i]][6] + \">\" + alle[index[i]] + \".\" + gene_13[index[i]][7] + \".\" + gene_13[index[i]][8])\n",
    "\n",
    "# Deduplicate to get unique feature labels\n",
    "sig3_repl_l = list(set(mut3_l))\n",
    "sig3_repl_m = list(set(mut3_m))\n",
    "sig3_repl_r = list(set(mut3_r))\n",
    "\n",
    "# Combine all unique feature labels for DataFrame columns\n",
    "feature_columns = sig1_repl + sig2_repl_l + sig2_repl_r + sig3_repl_l + sig3_repl_m + sig3_repl_r\n",
    "\n",
    "# Initialize a DataFrame with zeros, indexed by unique IDs and columns as feature labels\n",
    "df_combined = pd.DataFrame(0, index=unique_ids, columns=feature_columns)\n",
    "\n",
    "# Populate the DataFrame with counts for each mutation type\n",
    "for i in range(count):\n",
    "    try:\n",
    "        df_combined.loc[gene_id[index[i]], mut1[i]] += 1\n",
    "    except KeyError:\n",
    "        pass  # Skip if mutation type is not a column in the DataFrame\n",
    "    try:\n",
    "        df_combined.loc[gene_id[index[i]], mut2_l[i]] += 1\n",
    "    except KeyError:\n",
    "        pass\n",
    "    try:\n",
    "        df_combined.loc[gene_id[index[i]], mut2_r[i]] += 1\n",
    "    except KeyError:\n",
    "        pass\n",
    "    try:\n",
    "        df_combined.loc[gene_id[index[i]], mut3_l[i]] += 1\n",
    "    except KeyError:\n",
    "        pass\n",
    "    try:\n",
    "        df_combined.loc[gene_id[index[i]], mut3_m[i]] += 1\n",
    "    except KeyError:\n",
    "        pass\n",
    "    try:\n",
    "        df_combined.loc[gene_id[index[i]], mut3_r[i]] += 1\n",
    "    except KeyError:\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "f269c8c0-6c3e-4e88-9769-eded6b3d779f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>C&gt;T</th>\n",
       "      <th>C&gt;A</th>\n",
       "      <th>C&gt;G</th>\n",
       "      <th>T&gt;C</th>\n",
       "      <th>T&gt;A</th>\n",
       "      <th>T&gt;G</th>\n",
       "      <th>A.T&gt;A</th>\n",
       "      <th>T.A&gt;C</th>\n",
       "      <th>G.T&gt;C</th>\n",
       "      <th>C.G&gt;C</th>\n",
       "      <th>...</th>\n",
       "      <th>A.A&gt;C.C</th>\n",
       "      <th>T.G&gt;..A</th>\n",
       "      <th>C.A&gt;G.C</th>\n",
       "      <th>T.G&gt;..T</th>\n",
       "      <th>T.C&gt;CT.T</th>\n",
       "      <th>C.T&gt;C.A</th>\n",
       "      <th>G.T&gt;G.G</th>\n",
       "      <th>T.C&gt;T.T</th>\n",
       "      <th>A.A&gt;..C</th>\n",
       "      <th>C.G&gt;C.T</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>cancer/b</th>\n",
       "      <td>373</td>\n",
       "      <td>78</td>\n",
       "      <td>69</td>\n",
       "      <td>376</td>\n",
       "      <td>36</td>\n",
       "      <td>48</td>\n",
       "      <td>1</td>\n",
       "      <td>8</td>\n",
       "      <td>35</td>\n",
       "      <td>14</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>15</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>11</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>cancer/c</th>\n",
       "      <td>373</td>\n",
       "      <td>78</td>\n",
       "      <td>69</td>\n",
       "      <td>376</td>\n",
       "      <td>36</td>\n",
       "      <td>48</td>\n",
       "      <td>1</td>\n",
       "      <td>8</td>\n",
       "      <td>35</td>\n",
       "      <td>14</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>15</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>11</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>cancer/a</th>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>non-cancer/e</th>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "      <td>8</td>\n",
       "      <td>6</td>\n",
       "      <td>5</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>3</td>\n",
       "      <td>127</td>\n",
       "      <td>1</td>\n",
       "      <td>161</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>146</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>non-cancer/d</th>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "      <td>8</td>\n",
       "      <td>6</td>\n",
       "      <td>5</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>3</td>\n",
       "      <td>127</td>\n",
       "      <td>1</td>\n",
       "      <td>161</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>146</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 620 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              C>T  C>A  C>G  T>C  T>A  T>G  A.T>A  T.A>C  G.T>C  C.G>C  ...  \\\n",
       "cancer/b      373   78   69  376   36   48      1      8     35     14  ...   \n",
       "cancer/c      373   78   69  376   36   48      1      8     35     14  ...   \n",
       "cancer/a        4    0    0    0    0    0      0      0      0      0  ...   \n",
       "non-cancer/e   10    1    8    6    5    6      0      0      0      2  ...   \n",
       "non-cancer/d   10    1    8    6    5    6      0      0      0      2  ...   \n",
       "\n",
       "              A.A>C.C  T.G>..A  C.A>G.C  T.G>..T  T.C>CT.T  C.T>C.A  G.T>G.G  \\\n",
       "cancer/b            0        0       15        0         1        2        5   \n",
       "cancer/c            0        0       15        0         1        2        5   \n",
       "cancer/a            0        0        0        1         0        0        0   \n",
       "non-cancer/e        3      127        1      161         0        2        0   \n",
       "non-cancer/d        3      127        1      161         0        2        0   \n",
       "\n",
       "              T.C>T.T  A.A>..C  C.G>C.T  \n",
       "cancer/b           11        0        1  \n",
       "cancer/c           11        0        1  \n",
       "cancer/a            0        0        0  \n",
       "non-cancer/e        1      146        0  \n",
       "non-cancer/d        1      146        0  \n",
       "\n",
       "[5 rows x 620 columns]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_combined"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "3b3557c8-e9c2-49b1-8612-c2c422760f51",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reset the DataFrame index to convert the index into a column\n",
    "df_combined.reset_index(inplace=True)\n",
    "\n",
    "# Rename the newly created column from 'index' to 'label'\n",
    "# This is useful for further processing or for keeping track of the original index\n",
    "df_combined.rename(columns={'index': 'label'}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "b5ede8b8-d479-497c-a1e0-e3ea4b18db70",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Update the 'label' column to binary values based on the presence of 'non-cancer'\n",
    "# in the original index names. This is typically used for binary classification tasks.\n",
    "df_combined['label'] = df_combined['label'].apply(lambda x: 0 if 'non-cancer' in x else 1)\n",
    "\n",
    "# Here's what's happening in the lambda function:\n",
    "# - If 'non-cancer' is found in the 'label' value, it assigns 0 (indicating non-cancer cases).\n",
    "# - Otherwise, it assigns 1 (indicating cancer cases or any other case not explicitly labeled as non-cancer)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "caea4650-c3b9-4faf-a642-616880a6a61c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>C&gt;T</th>\n",
       "      <th>C&gt;A</th>\n",
       "      <th>C&gt;G</th>\n",
       "      <th>T&gt;C</th>\n",
       "      <th>T&gt;A</th>\n",
       "      <th>T&gt;G</th>\n",
       "      <th>A.T&gt;A</th>\n",
       "      <th>T.A&gt;C</th>\n",
       "      <th>G.T&gt;C</th>\n",
       "      <th>...</th>\n",
       "      <th>A.A&gt;C.C</th>\n",
       "      <th>T.G&gt;..A</th>\n",
       "      <th>C.A&gt;G.C</th>\n",
       "      <th>T.G&gt;..T</th>\n",
       "      <th>T.C&gt;CT.T</th>\n",
       "      <th>C.T&gt;C.A</th>\n",
       "      <th>G.T&gt;G.G</th>\n",
       "      <th>T.C&gt;T.T</th>\n",
       "      <th>A.A&gt;..C</th>\n",
       "      <th>C.G&gt;C.T</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>373</td>\n",
       "      <td>78</td>\n",
       "      <td>69</td>\n",
       "      <td>376</td>\n",
       "      <td>36</td>\n",
       "      <td>48</td>\n",
       "      <td>1</td>\n",
       "      <td>8</td>\n",
       "      <td>35</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>15</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>11</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>373</td>\n",
       "      <td>78</td>\n",
       "      <td>69</td>\n",
       "      <td>376</td>\n",
       "      <td>36</td>\n",
       "      <td>48</td>\n",
       "      <td>1</td>\n",
       "      <td>8</td>\n",
       "      <td>35</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>15</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>11</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "      <td>8</td>\n",
       "      <td>6</td>\n",
       "      <td>5</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>3</td>\n",
       "      <td>127</td>\n",
       "      <td>1</td>\n",
       "      <td>161</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>146</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "      <td>8</td>\n",
       "      <td>6</td>\n",
       "      <td>5</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>3</td>\n",
       "      <td>127</td>\n",
       "      <td>1</td>\n",
       "      <td>161</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>146</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 621 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   label  C>T  C>A  C>G  T>C  T>A  T>G  A.T>A  T.A>C  G.T>C  ...  A.A>C.C  \\\n",
       "0      1  373   78   69  376   36   48      1      8     35  ...        0   \n",
       "1      1  373   78   69  376   36   48      1      8     35  ...        0   \n",
       "2      1    4    0    0    0    0    0      0      0      0  ...        0   \n",
       "3      0   10    1    8    6    5    6      0      0      0  ...        3   \n",
       "4      0   10    1    8    6    5    6      0      0      0  ...        3   \n",
       "\n",
       "   T.G>..A  C.A>G.C  T.G>..T  T.C>CT.T  C.T>C.A  G.T>G.G  T.C>T.T  A.A>..C  \\\n",
       "0        0       15        0         1        2        5       11        0   \n",
       "1        0       15        0         1        2        5       11        0   \n",
       "2        0        0        1         0        0        0        0        0   \n",
       "3      127        1      161         0        2        0        1      146   \n",
       "4      127        1      161         0        2        0        1      146   \n",
       "\n",
       "   C.G>C.T  \n",
       "0        1  \n",
       "1        1  \n",
       "2        0  \n",
       "3        0  \n",
       "4        0  \n",
       "\n",
       "[5 rows x 621 columns]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_combined"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c863a184-c3b1-4b4d-8eb6-a8089583e9f3",
   "metadata": {},
   "source": [
    "# Splitting the dataset into training and testing sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "078e6714-8923-45e0-9221-f38d9c03c61c",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df_combined.drop('label', axis=1)  # Features\n",
    "y = df_combined['label']  # Target variable"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Perform the split"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "610ba2e1bbb70e86"
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "45ad0dee-4b63-4bdf-b4ab-967d1f365d57",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb113d71-54a7-4d5e-9ac5-c3d9fa34ca74",
   "metadata": {},
   "source": [
    "### XGBoost Classifier Setup\n",
    "### Define parameters for XGBoost"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6032c1f-b2e1-4036-9f37-1dd85cf8d119",
   "metadata": {},
   "source": [
    "##### Adjust depth, loss function and other parameters below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f15e019-c36e-4d01-9f0c-7f9976a9b55f",
   "metadata": {},
   "outputs": [],
   "source": [
    "params = {\n",
    "    'max_depth': 3,  # Maximum depth of a tree\n",
    "    'objective': 'binary:logistic',  # Objective function (multiclass classification)\n",
    "    'eta': 0.3,  # Learning rate \n",
    "    'eval_metric': 'logloss', # Evaluation metric\n",
    "    'random_state': 42 # Seed for reproducibility\n",
    "}\n",
    "num_rounds = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "476834f6-3ca2-43eb-8115-56408f8c56d3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.0\n"
     ]
    }
   ],
   "source": [
    "# Create DMatrix for XGBoost\n",
    "# DMatrix is an internal data structure that XGBoost uses optimized for both memory efficiency and training speed.\n",
    "# X_train: Features for the training data.\n",
    "# y_train: Labels for the training data.\n",
    "dtrain = xgb.DMatrix(X_train, label=y_train)\n",
    "\n",
    "# Similarly, prepare the test data as DMatrix for prediction.\n",
    "# X_test: Features for the test data.\n",
    "dtest = xgb.DMatrix(X_test, label=y_test)\n",
    "\n",
    "# Train the XGBoost model\n",
    "# `params`: Dictionary of parameters for XGBoost.\n",
    "# `dtrain`: Training data in DMatrix format.\n",
    "# `num_rounds`: Number of boosting rounds.\n",
    "bst = xgb.train(params, dtrain, num_rounds)\n",
    "\n",
    "# Predict with the trained model\n",
    "# `dtest`: Test data in DMatrix format.\n",
    "# The `predict` method outputs the probability of each instance being positive (in binary classification).\n",
    "preds = bst.predict(dtest)\n",
    "\n",
    "# Convert probabilities to binary output for evaluation\n",
    "# Threshold of 0.5: If the predicted probability is >0.5, classify as 1 (positive); otherwise, 0 (negative).\n",
    "preds_binary = [1 if x > 0.5 else 0 for x in preds]\n",
    "\n",
    "# Calculate and print the accuracy of the model\n",
    "# `y_test`: True labels for the test set.\n",
    "# `preds_binary`: Predicted binary labels for the test set.\n",
    "accuracy = accuracy_score(y_test, preds_binary)\n",
    "print(\"XGBoost Accuracy:\", accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3d62f3c-9eb6-4ee6-ba00-72303e3f6f57",
   "metadata": {},
   "source": [
    "# Gradient Boosting Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "245e4bc2-66cc-4fa6-a264-7a69f1de5023",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 1.0\n"
     ]
    }
   ],
   "source": [
    "# Gradient Boosting Classifier Setup\n",
    "# Initialize the classifier with specific hyperparameters:\n",
    "# - n_estimators: Number of boosting stages to be run. Here, it's set to 100.\n",
    "# - learning_rate: Rate at which the model learns. A lower rate requires more trees but can lead to better models.\n",
    "# - random_state: Seed used by the random number generator for reproducibility.\n",
    "clf = GradientBoostingClassifier(n_estimators=100, learning_rate=0.1, random_state=42)\n",
    "\n",
    "# Fit the model on the training data.\n",
    "# X_train: The training input samples.\n",
    "# y_train: The target values (class labels) as integers or strings.\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "# Predict the class labels for the test set.\n",
    "# X_test: The input samples for testing.\n",
    "y_pred = clf.predict(X_test)\n",
    "\n",
    "# Calculate the accuracy of the model.\n",
    "# y_test: The true labels for the test set.\n",
    "# y_pred: The predicted labels for the test set.\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "\n",
    "# Print the accuracy to evaluate the performance of the model.\n",
    "print(\"Gradient Boosting Classifier Accuracy:\", accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0483471e-c5cc-4f9f-b28e-84d1c8a039ed",
   "metadata": {},
   "source": [
    "# TabPFN\n",
    "##### Can use it by reducing features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "2ca967d4-7bef-4328-bcb8-01086a22d583",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n",
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "('The number of features for this classifier is restricted to ', 100)",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mValueError\u001B[0m                                Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[23], line 4\u001B[0m\n\u001B[1;32m      2\u001B[0m classifier \u001B[38;5;241m=\u001B[39m TabPFNClassifier(device\u001B[38;5;241m=\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mcpu\u001B[39m\u001B[38;5;124m'\u001B[39m, N_ensemble_configurations\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m4\u001B[39m)\n\u001B[1;32m      3\u001B[0m start \u001B[38;5;241m=\u001B[39m time\u001B[38;5;241m.\u001B[39mtime()\n\u001B[0;32m----> 4\u001B[0m \u001B[43mclassifier\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mfit\u001B[49m\u001B[43m(\u001B[49m\u001B[43mX_train\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43my_train\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m      5\u001B[0m y_eval, p_eval \u001B[38;5;241m=\u001B[39m classifier\u001B[38;5;241m.\u001B[39mpredict(X_test, return_winning_probability\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mTrue\u001B[39;00m)\n\u001B[1;32m      6\u001B[0m \u001B[38;5;28mprint\u001B[39m(\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mPrediction time: \u001B[39m\u001B[38;5;124m'\u001B[39m, time\u001B[38;5;241m.\u001B[39mtime() \u001B[38;5;241m-\u001B[39m start, \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mAccuracy\u001B[39m\u001B[38;5;124m'\u001B[39m, accuracy_score(y_test, y_eval))\n",
      "File \u001B[0;32m~/env/gene-tool/lib/python3.10/site-packages/tabpfn/scripts/transformer_prediction_interface.py:228\u001B[0m, in \u001B[0;36mTabPFNClassifier.fit\u001B[0;34m(self, X, y, overwrite_warning)\u001B[0m\n\u001B[1;32m    225\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39my_ \u001B[38;5;241m=\u001B[39m y\n\u001B[1;32m    227\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m X\u001B[38;5;241m.\u001B[39mshape[\u001B[38;5;241m1\u001B[39m] \u001B[38;5;241m>\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mmax_num_features:\n\u001B[0;32m--> 228\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mValueError\u001B[39;00m(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mThe number of features for this classifier is restricted to \u001B[39m\u001B[38;5;124m\"\u001B[39m, \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mmax_num_features)\n\u001B[1;32m    229\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mlen\u001B[39m(np\u001B[38;5;241m.\u001B[39munique(y)) \u001B[38;5;241m>\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mmax_num_classes:\n\u001B[1;32m    230\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mValueError\u001B[39;00m(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mThe number of classes for this classifier is restricted to \u001B[39m\u001B[38;5;124m\"\u001B[39m, \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mmax_num_classes)\n",
      "\u001B[0;31mValueError\u001B[0m: ('The number of features for this classifier is restricted to ', 100)"
     ]
    }
   ],
   "source": [
    "# import time\n",
    "# classifier = TabPFNClassifier(device='cpu', N_ensemble_configurations=4)\n",
    "# start = time.time()\n",
    "# classifier.fit(X_train, y_train)\n",
    "# y_eval, p_eval = classifier.predict(X_test, return_winning_probability=True)\n",
    "# print('Prediction time: ', time.time() - start, 'Accuracy', accuracy_score(y_test, y_eval))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c57ca2e1-d08f-443b-8252-0b0c66b58658",
   "metadata": {},
   "source": [
    "# K-Nearest Neighbors (KNN) Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "de070155-2013-4cec-a3c1-8776ab28b897",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 1.0\n"
     ]
    }
   ],
   "source": [
    "# Initialize the KNN Classifier\n",
    "# KNN is a simple, instance-based learning algorithm where the class of a sample is determined by the majority class among its k nearest neighbors.\n",
    "k = 3  # Specifies the number of neighbors to consider for making predictions. Here, we choose 3 neighbors.\n",
    "knn_classifier = KNeighborsClassifier(n_neighbors=k)  # Initialize the KNN classifier with the specified number of neighbors.\n",
    "\n",
    "# Training the Classifier\n",
    "# The classifier is trained (or \"fitted\") to the training data, which involves storing the feature vectors and class labels of the training samples.\n",
    "knn_classifier.fit(X_train, y_train)  # Fit the KNN model to the training data.\n",
    "\n",
    "# Predicting Labels for the Test Set\n",
    "# After the model is trained, it predicts the class labels for the provided test data based on the k nearest neighbors.\n",
    "y_pred = knn_classifier.predict(X_test)  # Use the trained KNN model to predict the class labels for the test set.\n",
    "\n",
    "# Evaluating Classifier Accuracy\n",
    "# The accuracy of the predictions is evaluated by comparing the predicted labels against the true labels of the test data.\n",
    "accuracy = accuracy_score(y_test, y_pred)  # Calculate the accuracy score of the KNN classifier.\n",
    "\n",
    "# Print the accuracy to provide insight into the performance of the model on unseen data.\n",
    "print(\"KNN Classifier Accuracy:\", accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8bc2127e-6a86-4716-9480-3f719ac42057",
   "metadata": {},
   "outputs": [],
   "source": [
    "hl.stop()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "gene-tool",
   "language": "python",
   "name": "gene-tool"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
